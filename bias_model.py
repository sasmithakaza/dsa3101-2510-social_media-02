# -*- coding: utf-8 -*-
"""finetuned_roberta_v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e8g-ZkFlDrnQdLjJQLrZulkrcXW6Fy2k

# Finetuning roBERTa for Political Media Bias Detection (model 2)

## Step 1: Data pre-processing

### Import packages & libraries
"""

pip install transformers datasets torch scikit-learn pandas

pip install --upgrade wandb --upgrade transformers

import numpy as np
import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from transformers import RobertaForSequenceClassification, RobertaTokenizer
from transformers import BertTokenizer
from datasets import Dataset
from transformers import BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.utils.class_weight import compute_class_weight
from google.colab import drive
drive.mount('/content/drive')

"""### Load & inspect dataset"""

# Load labeled data (for training and TTV split)
labeled_data_path = '/content/drive/My Drive/dsa4213/labelled_data_clean.csv'
df_labelled = pd.read_csv(labeled_data_path)

# Check the first few rows of data
df_labelled.head(10)

# Check the unique values in the 'Label' column and their counts
label_counts = df_labelled['bias_text'].value_counts()

# Display the unique labels and their counts
print(label_counts)

# Clean the 'body' column to ensure all entries are strings
df_labelled['body'] = df_labelled['body'].fillna('').astype(str)

# Load unlabelled data (for prediction)
labeled_data_path = '/content/drive/My Drive/dsa4213/unlabelled_data_clean.csv'
df_unlabelled = pd.read_csv(labeled_data_path)

# Check the first few rows of data
df_unlabelled.head(10)

"""## Step 2: Tokenize the text and prepare the data for roBERTa"""

# Load the roBERTa tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

# Preprocess function to tokenize text (using 'body' column)
def preprocess_function(examples):
    return tokenizer(examples['body'], truncation=True, padding=True, max_length=256)

# Create label mapping
print("\nActual labels in dataset:")
print(df_labelled['bias_text'].unique())

label_mapping = {'center': 0, 'left': 1, 'right': 2}

# Encode labels to integers
df_labelled['labels'] = df_labelled['bias_text'].map(label_mapping)

# Check if any labels failed to map
if df_labelled['labels'].isna().any():
    print("\n‚ö†Ô∏è WARNING: Some labels couldn't be mapped!")
    print("Unmapped labels:")
    print(df_labelled[df_labelled['labels'].isna()]['bias_text'].value_counts())
    print("\nüî¥ Please fix the label_mapping dictionary above!")
    df_labelled = df_labelled.dropna(subset=['labels'])

# Convert to int
df_labelled['labels'] = df_labelled['labels'].astype(int)

print("\nMapped label distribution:")
print(df_labelled['labels'].value_counts().sort_index())

"""## Step 3: TTV Split"""

# Split the labeled data into train and validation sets WITH STRATIFICATION
train_df, val_df = train_test_split(
    df_labelled,
    test_size=0.15,
    random_state=42,
    stratify=df_labelled['labels']
)

print(f"\nTrain set size: {len(train_df)}")
print("Train label distribution:")
print(train_df['labels'].value_counts().sort_index())

print(f"\nValidation set size: {len(val_df)}")
print("Validation label distribution:")
print(val_df['labels'].value_counts().sort_index())

# Convert pandas DataFrame to Hugging Face Dataset format
train_dataset = Dataset.from_pandas(train_df[['body', 'labels']])
val_dataset = Dataset.from_pandas(val_df[['body', 'labels']])

# Tokenize the datasets
train_dataset = train_dataset.map(preprocess_function, batched=True)
val_dataset = val_dataset.map(preprocess_function, batched=True)

# Set format for PyTorch (IMPORTANT: includes 'labels')
train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])

# For the unlabeled dataset, tokenize the 'body' column
df_unlabelled['body'] = df_unlabelled['body'].apply(str)
unlabeled_dataset = Dataset.from_pandas(df_unlabelled[['body']])
unlabeled_dataset = unlabeled_dataset.map(preprocess_function, batched=True)
unlabeled_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])

# Check tokenized output (optional)
print("\nTokenized Train Dataset Example:")
print(train_dataset[0])

decoded_text = tokenizer.decode(train_dataset[0]['input_ids'])
print(f"\nDecoded text preview: {decoded_text[:200]}...")

"""## Step 4: Compute class weights and use custom trainer"""

# compute class weights since classes/ labels are imbalanced
print("COMPUTING CLASS WEIGHTS")

class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(train_df['labels']),
    y=train_df['labels']
)
class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)

print(f"\nClass weights (to handle imbalance):")
for i, weight in enumerate(class_weights):
    print(f"  Class {i}: {weight:.4f}")

# custom trainer with weighted classes/ labels
class WeightedTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits

        # Apply class weights to loss
        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor.to(logits.device), label_smoothing=0.1)
        loss = loss_fct(logits, labels)

        return (loss, outputs) if return_outputs else loss

# evaluation metrics function (simplified, overall metrics only)
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    preds = predictions.argmax(axis=1)

    # overall metrics only
    acc = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds, average='weighted')
    precision = precision_score(labels, preds, average='weighted')
    recall = recall_score(labels, preds, average='weighted')

    # optional: prediction distribution
    unique, counts = np.unique(preds, return_counts=True)
    print(f"\nüìä Prediction distribution: {dict(zip(unique, counts))}")

    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Step 5: Finetune roBERTa"""

# load roBERTa model
num_labels = len(df_labelled['labels'].unique())
print(f"\nNumber of classes: {num_labels}")

from transformers import RobertaForSequenceClassification

model = RobertaForSequenceClassification.from_pretrained(
    'roberta-base',
    num_labels=num_labels,
    problem_type="single_label_classification",
    hidden_dropout_prob=0.3,           # ADD THIS
    attention_probs_dropout_prob=0.3,  # ADD THIS
)

# finetuning parameters
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=10,                  # longer training for full convergence
    per_device_train_batch_size=16,       # larger batch size improves stability
    per_device_eval_batch_size=32,        # faster evaluation
    learning_rate=1e-5,                   # lower LR for stable fine-tuning
    warmup_ratio=0.1,                     # small warmup helps convergence
    weight_decay=0.1,                    # standard weight decay
    logging_strategy="epoch",             # only log per epoch
    eval_strategy="epoch",                # evaluate per epoch
    save_strategy="epoch",                # save per epoch
    save_total_limit=3,                   # keep 3 best checkpoints
    load_best_model_at_end=True,          # automatically load best model
    metric_for_best_model="f1",           # optimize for F1 score
    greater_is_better=True,
    report_to="none",
    seed=42,
    fp16=torch.cuda.is_available(),       # use mixed precision if GPU supports
    gradient_accumulation_steps=2,        # larger effective batch possible
    dataloader_num_workers=2,             # speed up data loading
    remove_unused_columns=False,          # avoid data loss
)

# initialise weighted trainer
trainer = WeightedTrainer(  # or FocalLossTrainer
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
)

# start training
trainer.train()

# save model to gdrive
model.save_pretrained('/content/drive/My Drive/dsa3101/bias_detection_model_roberta')
tokenizer.save_pretrained('/content/drive/My Drive/dsa3101/bias_detection_model_roberta')

print("\n‚úì Model and tokenizer saved to Google Drive!")

"""## Step 6: Evaluate model performance"""

# evaluate model performance
print("FINAL EVALUATION")
results = trainer.evaluate()
print("\nEvaluation Results:", results)

# prediction check/ verification
print("PREDICTION SANITY CHECK")

# Get predictions on validation set
predictions = trainer.predict(val_dataset)
preds = predictions.predictions.argmax(axis=1)

print("\nValidation set PREDICTION distribution:")
unique, counts = np.unique(preds, return_counts=True)
for label, count in zip(unique, counts):
    percentage = count / len(preds) * 100
    print(f"  Class {label}: {count} ({percentage:.1f}%)")

print("\nValidation set TRUE label distribution:")
true_labels = val_df['labels'].values
unique, counts = np.unique(true_labels, return_counts=True)
for label, count in zip(unique, counts):
    percentage = count / len(true_labels) * 100
    print(f"  Class {label}: {count} ({percentage:.1f}%)")

if len(np.unique(preds)) < num_labels:
    print("\nüî¥ WARNING: Model is not predicting all classes!")
    print("   The model has collapsed to predicting only majority classes.")
    print("   Consider:")
    print("   1. Increasing class weights further")
    print("   2. Oversampling minority classes")
    print("   3. Using focal loss")
else:
    print("\n‚úÖ SUCCESS: Model is predicting all classes!")

"""## Step 7: Make predictions on unlabelled data"""

# Make predictions
predictions_unlabeled = trainer.predict(unlabeled_dataset)
predicted_labels = predictions_unlabeled.predictions.argmax(axis=1)
predicted_probs = torch.softmax(torch.tensor(predictions_unlabeled.predictions), dim=1).numpy()

# Convert back to label names
reverse_label_mapping = {v: k for k, v in label_mapping.items()}
df_unlabelled['predicted_label'] = [reverse_label_mapping[label] for label in predicted_labels]

# Add confidence scores
df_unlabelled['confidence'] = predicted_probs.max(axis=1)

# Add probabilities for each class
for i, label_name in enumerate(['neutral', 'left', 'right']):
    df_unlabelled[f'prob_{label_name}'] = predicted_probs[:, i]

# Show prediction distribution
print("\nPrediction distribution on unlabeled data:")
print(df_unlabelled['predicted_label'].value_counts())

print(f"\nAverage confidence: {df_unlabelled['confidence'].mean():.4f}")

# Save predictions
df_unlabelled.to_csv('/content/drive/My Drive/dsa3101/predictions.csv', index=False)
print("\n‚úì Predictions saved to 'predictions.csv'!")

# Show some examples
print("\nSample predictions:")
print(df_unlabelled[['body', 'predicted_label', 'confidence']].head(10))